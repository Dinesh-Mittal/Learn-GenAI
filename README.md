# Learn-GenAI
Collection of excellent material, sites, references for learning Gen-AI


# How LLM Model Works


# LLM Model Use

Explanation of LLM Model Parameters - https://www.vellum.ai/llm-parameters/seed

## KV Caching in LLM Models
Tried implementing extremely simple version of KV caching in LLMs. This is crucial in LLM deployment at scale, it reuses Key and Value matrices for consecutive computations. 
Open to feedback:
Blog link: https://sagarsarkale.com/blog/genai/kv-caching-demo/
Github: https://github.com/sagarsrc/kv-caching 
